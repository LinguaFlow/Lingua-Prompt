import os
import time
import re
from flask import Flask, request, jsonify
from typing import List, Dict, Optional
import google.generativeai as genai
from flask.cli import load_dotenv


BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
load_dotenv(os.path.join(BASE_DIR, ".env"))

load_dotenv()
app = Flask(__name__)


# Configuration constants
class Config:
    """Application configuration settings."""
    # Get API key from environment variable
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    MODEL_NAME = os.getenv("MODEL_NAME")
    DEFAULT_TEMPERATURE = float(os.getenv("DEFAULT_TEMPERATURE"))
    DEFAULT_DIFFICULTY = os.getenv("DEFAULT_DIFFICULTY")
    DEFAULT_NUM_EXAMPLES = int(os.getenv("DEFAULT_NUM_EXAMPLES"))
    MAX_RETRIES = int(os.getenv("MAX_RETRIES")) # seconds

    # JLPT ë ˆë²¨ ì„¤ëª…
    LEVEL_DESCRIPTIONS = {
        "n5": "Beginner level (N5) - Absolute beginner: Able to understand basic Japanese phrases and sentences when spoken slowly. Can read hiragana, katakana, and about 100 kanji. Vocabulary knowledge includes approximately 800 words covering basic needs and everyday situations. Can introduce oneself and engage in very simple conversations.",

        "n4": "Basic level (N4) - Basic daily expressions: Can understand conversations about everyday topics when spoken slowly. Able to read and write about 300 kanji and comprehend simple passages on familiar topics. Vocabulary knowledge extends to roughly 1,500 words. Can handle basic social interactions and express simple opinions or preferences.",

        "n3": "Intermediate level (N3) - Everyday communication: Can understand coherent Japanese used in daily situations at near-natural speed. Able to read approximately 650 kanji and comprehend newspaper headlines and straightforward articles. Vocabulary knowledge covers about 3,700 words. Can express opinions, describe experiences, and maintain conversations on familiar topics with some fluency.",

        "n2": "Upper intermediate level (N2) - Practical communication: Can understand natural-speed Japanese in a variety of situations. Able to read 1,000+ kanji and comprehend newspapers, general articles, and some specialized content with occasional dictionary use. Vocabulary knowledge extends to roughly 6,000 words. Can communicate effectively in most social and professional contexts, expressing ideas with reasonable clarity and accuracy.",

        "n1": "Advanced level (N1) - Natural, native-like expressions: Can understand Japanese used in a wide range of sophisticated contexts. Able to read 2,000+ kanji and comprehend complex texts including abstract concepts, literary works, and specialized content. Vocabulary knowledge exceeds 10,000 words. Can communicate with nuance and subtlety, demonstrating near-native fluency across various situations and topics.",

        "standard": "Intermediate level (default) - Represents a balanced proficiency level approximately equivalent to N3, suitable for everyday communication and basic professional interactions. Includes knowledge of common vocabulary, grammar patterns, and cultural references sufficient for most general purposes."
    }

    # Detailed grammar instructions by level
    DETAILED_INSTRUCTIONS = {
        "n5": (
            "Create very simple, short sentences using basic subject-object-verb structure. "
            "Use only basic vocabulary (around 800 words) and masu-form present tense. "
            "Include basic particles (ã¯, ã‚’, ã«, ã§, etc.) and simple question forms. "
            "Use simple time expressions (ä»Šæ—¥, æ˜æ—¥, etc.) and straightforward counters. "
            "Avoid conjugations beyond the essentials (masu-form, simple negative). "
            "Keep sentences under 8-10 words with minimal compound structures."
        ),

        "n4": (
            "Use basic daily expressions with simple past and present tense forms. "
            "Include te-form for requests, permissions, and ongoing actions. "
            "Incorporate basic conjunctions (ãã—ã¦, ã§ã‚‚, ã‹ã‚‰) and time connectors. "
            "Introduce simple potential, imperative, and volitional forms. "
            "Use ~ãŸã„ for expressing desires and basic compound sentences. "
            "Keep grammar straightforward and beginner-friendly with vocabulary of around 1,500 words. "
            "Limit use of specialized terminology and complex modifier structures."
        ),

        "n3": (
            "Include both casual and polite forms with conditional structures (ï½ãŸã‚‰, ï½ã¨, ï½ã°, ï½ãªã‚‰). "
            "Use transitive/intransitive verb pairs appropriately in context. "
            "Incorporate provisional, causative, and passive expressions. "
            "Employ more complex particles (ã«ã¤ã„ã¦, ã«ã‚ˆã£ã¦) and conjunction patterns. "
            "Use everyday vocabulary (around 3,700 words) with some specialized terms. "
            "Include appropriate sentence-ending particles for natural conversation. "
            "Demonstrate proper use of embedded clauses and complex modifiers."
        ),

        "n2": (
            "Employ more complex grammar including honorific and humble expressions. "
            "Use keigo where appropriate (å°Šæ•¬èª, è¬™è­²èª, ä¸å¯§èª) in social contexts. "
            "Include advanced conditional forms and complex cause-effect relationships. "
            "Incorporate idiomatic phrasing and expressions for practical contexts. "
            "Use specialized vocabulary (around 6,000 words) relevant to professional settings. "
            "Show proper use of complex modifiers, nominalizers, and sentence patterns. "
            "Demonstrate appropriate register switching based on social context."
        ),

        "n1": (
            "Use advanced, native-like expressions including formal honorifics, "
            "humble language, and situationally-appropriate speech styles. "
            "Incorporate nuanced idioms, proverbs, and culturally-specific references. "
            "Employ sophisticated rhetorical techniques and literary expressions. "
            "Use specialized vocabulary (10,000+ words) with proper field-specific terminology. "
            "Include complex grammatical structures rarely found in textbooks. "
            "Provide cultural depth through appropriate speech patterns and sophisticated expressions. "
            "Demonstrate native-like command of subtle connotations and implications."
        ),

        "standard": (
            "Use general intermediate grammar including plain and polite forms. "
            "Incorporate common conditional structures and modal expressions. "
            "Use moderate vocabulary (approximately 3,000-4,000 words) with some specialized terms. "
            "Balance complexity and clarity in sentence structures. "
            "Include commonly used idiomatic expressions and natural phrasing. "
            "Demonstrate appropriate use of casual and formal speech based on context."
        ),
    }

    # Usage variation hints by level
    USAGE_VARIATIONS = {
        "n5": (
            "Focus on clear, everyday usage only. "
            "Use simple sentences in common situations like self-introductions, ordering food, "
            "asking directions, and basic shopping interactions. "
            "Limit contexts to classroom, home, and simple travel scenarios. "
            "Avoid slang, colloquialisms, and regional variations. "
            "Present information using only the most fundamental grammatical patterns."
        ),

        "n4": (
            "Show basic usage in common daily situations. "
            "Include simple past experiences, future plans, and basic opinions. "
            "Demonstrate usage in everyday contexts like shopping, dining, travel, and basic workplace interactions. "
            "Introduce simple expressions of preference, ability, and necessity. "
            "Keep examples concrete and related to personal daily routines and needs. "
            "Use straightforward question-answer patterns typical of beginner conversations."
        ),

        "n3": (
            "Mix casual and polite speech in everyday contexts. "
            "Show appropriate switching between speech styles with friends versus acquaintances. "
            "Include usage examples for social gatherings, workplace situations, and service encounters. "
            "Demonstrate expressing opinions, making requests, giving reasons, and discussing plans. "
            "Show proper use in both spoken and written contexts (emails, text messages, etc.). "
            "Include examples of natural conversation flow with appropriate interjections and responses."
        ),

        "n2": (
            "Show usage in a variety of social settings and registers. "
            "Demonstrate appropriate language for business meetings, customer service, and formal occasions. "
            "Include examples of persuasive, descriptive, and explanatory language. "
            "Show proper keigo usage in hierarchical relationships and customer interactions. "
            "Incorporate examples from mass media, academic contexts, and professional settings. "
            "Demonstrate appropriately indirect expressions for requests, refusals, and criticism. "
            "Include examples of situation-specific speech patterns and expressions."
        ),

        "n1": (
            "Demonstrate formal, informal, regional, and professional contexts where relevant. "
            "Include examples of highly formal speech for ceremonial occasions and important business. "
            "Show nuanced differences in expression based on age, gender, social status, and regional background. "
            "Incorporate examples from literature, news media, academic writing, and specialized fields. "
            "Demonstrate subtle differences in nuance between similar expressions. "
            "Show appropriate usage in sensitive situations requiring tact and cultural awareness. "
            "Include examples of rhetorical techniques for persuasion, humor, and emotional impact. "
            "Demonstrate understanding of historical language changes and contemporary trends."
        ),

        "standard": (
            "Use typical everyday polite and casual speech. "
            "Balance formality appropriate to common social and professional situations. "
            "Include examples from daily conversations, routine work interactions, and social media. "
            "Show moderate level of politeness differentiation based on context. "
            "Demonstrate natural conversational patterns with appropriate back-channeling. "
            "Include examples relevant to both spoken and written communication."
        ),
    }

    # Valid JLPT levels
    VALID_LEVELS = ["n5", "n4", "n3", "n2", "n1", "standard"]

    # Verb conjugation descriptions in English (new addition)
    VERB_CONJUGATION_DESCRIPTIONS = {
        "è¾æ›¸å½¢": "Dictionary form (basic form)",
        "ã¾ã™å½¢": "Masu form (polite present affirmative)",
        "ã¦å½¢": "Te-form (connecting form, used for requests, ongoing actions)",
        "ãŸå½¢": "Ta-form (past tense)",
        "å¦å®šå½¢": "Negative form (present, plain)",
        "ãªã„å½¢": "Nai-form (negative form, base for other negatives)",
        "ãªã‹ã£ãŸå½¢": "Nakatta-form (past negative)",
        "å‘½ä»¤å½¢": "Imperative form (commands)",
        "ç¦æ­¢å½¢": "Prohibitive form (negative commands)",
        "æ„å‘å½¢": "Volitional form (expressing intention)",
        "æ¡ä»¶å½¢": "Conditional form (if...then constructions)",
        "å¯èƒ½å½¢": "Potential form (ability to do something)",
        "å—èº«å½¢": "Passive form (being acted upon)",
        "ä½¿å½¹å½¢": "Causative form (making/letting someone do something)",
        "ä½¿å½¹å—èº«å½¢": "Causative-passive form (being made to do something)",
        "ä»®å®šå½¢": "Hypothetical form (if/when scenarios)",
        "æ•¬èª": "Honorific form (showing respect)",
        "è¬™è­²èª": "Humble form (showing humility for own actions)",
        "ä¸å¯§èª": "Polite form (general politeness)",
    }

    # Korean translation style guidelines (new addition)
    KOREAN_TRANSLATION_GUIDELINES = {
        "n5": (
            "ê°€ì¥ ê¸°ë³¸ì ì¸ êµ¬ë¬¸ê³¼ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­í•˜ì„¸ìš”. "
            "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë˜, ë‹¨ìˆœí•˜ê³  ì§ì ‘ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ì¼ìƒ ìƒí™œì—ì„œ ìì£¼ ì“°ì´ëŠ” ê¸°ë³¸ì ì¸ í‘œí˜„ìœ¼ë¡œ ë²ˆì—­í•˜ì„¸ìš”. "
            "í•œêµ­ì–´ ë¬¸ì¥ì„ ì§§ê³  ëª…í™•í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”."
        ),

        "n4": (
            "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë˜, ì¼ë³¸ì–´ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ì •í™•íˆ ë°˜ì˜í•˜ì„¸ìš”. "
            "ì¼ìƒì ì¸ í‘œí˜„ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. "
            "í•œêµ­ì¸ì´ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ì¼ë³¸ì–´ì˜ ì¡´ëŒ“ë§ê³¼ ë°˜ë§ êµ¬ë¶„ì„ ì ì ˆíˆ ë²ˆì—­í•˜ì„¸ìš”."
        ),

        "n3": (
            "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ìœ¼ë¡œ ë²ˆì—­í•˜ë˜, ë¬¸ë§¥ì— ë§ê²Œ ì˜ì—­í•˜ì„¸ìš”. "
            "ì§ì—­ë³´ë‹¤ ì˜ë¯¸ ì „ë‹¬ì— ì¤‘ì ì„ ë‘ì–´ ë²ˆì—­í•˜ì„¸ìš”. "
            "í•œêµ­ì–´ ê³ ìœ ì˜ ê´€ìš©ì  í‘œí˜„ì„ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”. "
            "ëŒ€í™” ìƒí™©ì— ë§ëŠ” ì ì ˆí•œ ì–´ì¡°ì™€ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
        ),

        "n2": (
            "ì¼ë³¸ì–´ ë‰˜ì•™ìŠ¤ë¥¼ ì‚´ë¦¬ë©´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. "
            "í•œêµ­ì–´ ê´€ìš©êµ¬ì™€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”. "
            "ë¬¸ë§¥ê³¼ ìƒí™©ì— ë§ê²Œ ì ì ˆí•œ ì–´íœ˜ì™€ í‘œí˜„ì„ ì„ íƒí•˜ì„¸ìš”. "
            "ì‚¬íšŒì  ë§¥ë½ê³¼ ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ì¡´ëŒ€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."
        ),

        "n1": (
            "ê³ ê¸‰ í•œêµ­ì–´ í‘œí˜„ê³¼ ê´€ìš©ì  ì–´íœ˜ë¥¼ í™œìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•˜ì„¸ìš”. "
            "ì›ë¬¸ì˜ ë‰˜ì•™ìŠ¤ì™€ ë¬¸ì²´ë¥¼ ìµœëŒ€í•œ ì‚´ë¦¬ë©´ì„œ ì„¸ë ¨ëœ í•œêµ­ì–´ë¡œ í‘œí˜„í•˜ì„¸ìš”. "
            "ë¬¸í™”ì  ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ í•œêµ­ì–´ ë…ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬ë˜ë„ë¡ ë²ˆì—­í•˜ì„¸ìš”. "
            "ìƒí™©ê³¼ ì¸ê°„ê´€ê³„ì— ì í•©í•œ ì¡´ëŒ€ í‘œí˜„ê³¼ ë§íˆ¬ë¥¼ ì •í™•íˆ êµ¬ì‚¬í•˜ì„¸ìš”."
        ),

        "standard": (
            "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ìœ¼ë¡œ ì˜ë¯¸ë¥¼ ì •í™•íˆ ì „ë‹¬í•˜ì„¸ìš”. "
            "ë¬¸ë§¥ì— ë§ê²Œ ì ì ˆí•œ ì–´íœ˜ì™€ í‘œí˜„ì„ ì„ íƒí•˜ì„¸ìš”. "
            "í•œêµ­ì–´ í™”ìê°€ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ìƒí™©ì— ë§ëŠ” ì ì ˆí•œ ì¡´ëŒ€ í‘œí˜„ê³¼ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
        ),
    }


class LLMService:
    """Service for interacting with the Gemini API."""

    @staticmethod
    def initialize_gemini():
        """Initialize Gemini API."""
        if not Config.GEMINI_API_KEY:
            app.logger.error("API key not configured. Set GEMINI_API_KEY environment variable.")
            return False

        try:
            genai.configure(api_key=Config.GEMINI_API_KEY)
            return True
        except Exception as e:
            app.logger.error(f"Failed to initialize Gemini API: {str(e)}")
            return False

    @staticmethod
    def call_llm(
            prompt: str,
            temperature: float = Config.DEFAULT_TEMPERATURE
    ) -> Optional[str]:
        """
        Call the Gemini API and get a response with improved response handling.
        """
        if not Config.GEMINI_API_KEY:
            app.logger.error("API key not configured. Set GEMINI_API_KEY environment variable.")
            return None

        # Initialize Gemini API if not already initialized
        LLMService.initialize_gemini()

        retry_count = 0

        while retry_count < Config.MAX_RETRIES:
            try:
                # Load the model
                model = genai.GenerativeModel(Config.MODEL_NAME)

                # Generate content
                response = model.generate_content(
                    prompt,
                    generation_config={
                        "temperature": temperature,
                        "top_p": 0.95,
                        "top_k": 40,
                        "max_output_tokens": 2048
                    }
                )

                if response:
                    # ê°œì„ ëœ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§
                    try:
                        # ë¨¼ì € response.text ì‹œë„
                        return response.text
                    except Exception as text_error:
                        app.logger.warning(f"response.text failed: {text_error}")

                        # ëŒ€ì•ˆ ë°©ë²•: candidatesë¥¼ í†µí•œ ì ‘ê·¼
                        try:
                            if response.candidates and len(response.candidates) > 0:
                                candidate = response.candidates[0]
                                if candidate.content and candidate.content.parts:
                                    # partsì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                    text_parts = []
                                    for part in candidate.content.parts:
                                        if hasattr(part, 'text') and part.text:
                                            text_parts.append(part.text)

                                    if text_parts:
                                        return ''.join(text_parts)
                                    else:
                                        app.logger.error("No text found in response parts")
                                else:
                                    app.logger.error("No content or parts in candidate")
                            else:
                                app.logger.error("No candidates in response")
                        except Exception as parts_error:
                            app.logger.error(f"Failed to extract text from parts: {parts_error}")

                    # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš°
                    app.logger.error("All text extraction methods failed")

                else:
                    app.logger.error("Empty response from Gemini API")

                retry_count += 1
                if retry_count < Config.MAX_RETRIES:
                    time.sleep(2)

            except Exception as e:
                app.logger.error(f"Gemini API call error: {str(e)}")
                retry_count += 1
                if retry_count < Config.MAX_RETRIES:
                    time.sleep(2)
                else:
                    return None

        return None


class JapaneseExampleGenerator:
    """Generator for Japanese example sentences with Korean translations."""

    def __init__(self):
        pass

    @staticmethod
    def generate_examples(
            word: str,
            difficulty: str = Config.DEFAULT_DIFFICULTY,
            num_examples: int = Config.DEFAULT_NUM_EXAMPLES,
            max_retries: int = 3  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
    ) -> List[Dict[str, str]]:
        """
        Generate natural Japanese example sentences with guaranteed count.
        """
        # ë” ë§ì€ ì˜ˆë¬¸ì„ ìš”ì²­í•˜ì—¬ í•„í„°ë§ í›„ì—ë„ ì¶©ë¶„íˆ ë‚¨ë„ë¡ í•¨
        requested_num = min(num_examples + 3, 8)  # 3ê°œ ë” ìš”ì²­ (ìµœëŒ€ 8ê°œ)

        # ì¬ì‹œë„ ë¡œì§
        for attempt in range(max_retries + 1):
            try:
                # Get level-specific components
                level_text = Config.LEVEL_DESCRIPTIONS.get(difficulty, Config.LEVEL_DESCRIPTIONS["standard"])
                instruction_detail = Config.DETAILED_INSTRUCTIONS.get(difficulty,
                                                                      Config.DETAILED_INSTRUCTIONS["standard"])
                variation_instruction = Config.USAGE_VARIATIONS.get(difficulty, Config.USAGE_VARIATIONS["standard"])
                korean_translation_guide = Config.KOREAN_TRANSLATION_GUIDELINES.get(difficulty,
                                                                                    Config.KOREAN_TRANSLATION_GUIDELINES[
                                                                                        "standard"])

                # ì¬ì‹œë„ì¼ ê²½ìš° ì˜¨ë„ ê°’ì„ ì•½ê°„ ë³€ê²½í•˜ì—¬ ë‹¤ì–‘í•œ ê²°ê³¼ ìœ ë„
                temperature = Config.DEFAULT_TEMPERATURE
                if attempt > 0:
                    temperature = min(0.9, Config.DEFAULT_TEMPERATURE + 0.1 * attempt)
                    app.logger.info(f"Retry attempt {attempt} with temperature {temperature}")

                # Build the prompt with requested_num (ë” ë§ì€ ì˜ˆë¬¸ ìš”ì²­)
                prompt = JapaneseExampleGenerator._build_example_prompt(
                    word, level_text, instruction_detail, variation_instruction, korean_translation_guide, requested_num
                )

                # Call the language model and parse its response
                response = LLMService.call_llm(prompt, temperature=temperature)

                if not response:
                    app.logger.warning(f"No response from LLM (attempt {attempt + 1}/{max_retries + 1})")
                    continue

                # Parse examples from the response
                examples = JapaneseExampleGenerator._parse_examples(response, word)

                # ìœ íš¨í•œ ì˜ˆì‹œê°€ ì¶©ë¶„í•œì§€ í™•ì¸
                valid_examples = [ex for ex in examples if
                                  ex["japanese"] != "ä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚" and
                                  ex["japanese"] != "é©åˆ‡ãªä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"]

                app.logger.info(f"Generated {len(valid_examples)} valid examples out of {num_examples} requested")

                # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸
                if len(valid_examples) >= num_examples:
                    # ì •í™•íˆ ìš”ì²­ëœ ê°œìˆ˜ë§Œ ë°˜í™˜
                    return valid_examples[:num_examples]

                # ë¶€ì¡±í•œ ê²½ìš° ì¶”ê°€ ìƒì„± ì‹œë„
                if len(valid_examples) > 0 and attempt < max_retries:
                    remaining = num_examples - len(valid_examples)
                    app.logger.info(f"Need {remaining} more examples, attempting additional generation")

                    # ì¶”ê°€ ì˜ˆë¬¸ ìƒì„±
                    additional_prompt = JapaneseExampleGenerator._build_example_prompt(
                        word, level_text, instruction_detail, variation_instruction,
                        korean_translation_guide, remaining + 2  # ì—¬ìœ ë¶„ ì¶”ê°€
                    )

                    additional_temp = min(0.95, temperature + 0.15)
                    additional_response = LLMService.call_llm(additional_prompt, temperature=additional_temp)

                    if additional_response:
                        additional_examples = JapaneseExampleGenerator._parse_examples(additional_response, word)
                        additional_valid = [ex for ex in additional_examples if
                                            ex["japanese"] != "ä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚" and
                                            ex["japanese"] != "é©åˆ‡ãªä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"]

                        # ê¸°ì¡´ ì˜ˆë¬¸ê³¼ í•©ì¹˜ê¸°
                        valid_examples.extend(additional_valid)
                        app.logger.info(f"Added {len(additional_valid)} more examples, total: {len(valid_examples)}")

                        # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆìœ¼ë©´ ë°˜í™˜
                        if len(valid_examples) >= num_examples:
                            return valid_examples[:num_examples]

                # ì—¬ì „íˆ ë¶€ì¡±í•œ ê²½ìš° ë‹¤ìŒ ì‹œë„ë¡œ
                if len(valid_examples) < max(1, int(num_examples * 0.5)):
                    continue

                # ìµœì†Œí•œì˜ ì˜ˆë¬¸ì´ë¼ë„ ìˆìœ¼ë©´ ë°˜í™˜ (ë¶€ë¶„ì  ì„±ê³µ)
                if valid_examples:
                    app.logger.warning(f"Returning {len(valid_examples)} examples instead of {num_examples}")
                    return valid_examples

            except Exception as e:
                app.logger.error(f"Error during example generation (attempt {attempt + 1}/{max_retries + 1}): {str(e)}")
                if attempt < max_retries:
                    continue

        # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš°
        app.logger.error("All generation attempts failed")
        return [
            {
                "context": "",
                "japanese": "ä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
                "korean": "ì˜ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ã€‚"
            }
        ]

    @staticmethod
    def _build_example_prompt(
            word: str,
            level_text: str,
            instruction_detail: str,
            variation_instruction: str,
            korean_translation_guide: str,
            num_examples: int
    ) -> str:
        """
        Build the detailed prompt for the LLM to generate examples.

        Args:
            word: Target Japanese word
            level_text: Description of the JLPT level
            instruction_detail: Detailed grammar instructions
            variation_instruction: Usage variation hints
            korean_translation_guide: Guidelines for Korean translation
            num_examples: Number of examples to generate

        Returns:
            Formatted prompt string
        """
        return f"""
        # Japanese Example Sentence Generator

        ## Role
        You are an experienced Japanese language teacher creating authentic example sentences for learners.

        ## Target Word
        "{word}"

        ## Requirements
        - Generate EXACTLY {num_examples} example sentences using the word "{word}"
        - Use {level_text} Japanese appropriate for the learner's level
        - {instruction_detail}
        - {variation_instruction}
        - EVERY sentence must be COMPLETE. Never leave sentences unfinished or ending with "...".
        - Ensure each sentence has a proper subject, predicate, and any necessary objects or complements.

        ## Context Guidelines
        - Create realistic situations from daily Japanese life (home, work, school, restaurants, etc.)
        - Show the word being used in different contexts and by different speakers
        - If the word has multiple meanings, demonstrate each major usage
        - EXTREMELY IMPORTANT: Ensure each example is semantically correct and natural in Japanese
        - For verbs like "é£Ÿã¹ã‚‹" (to eat), only use objects that can actually be eaten in Japanese culture
        - For action verbs, ensure the actions are logical and natural in real-life contexts

        ## Korean Translation Guidelines
        - {korean_translation_guide}
        - Focus on natural Korean translation that a native Korean speaker would actually use
        - Don't translate word-for-word, but convey the meaning in natural Korean
        - Maintain the appropriate level of formality from the Japanese sentence
        - Use Korean expressions and idioms that match the context where appropriate
        - Make sure Korean translations are complete sentences that fully express the meaning

        ## Output Format
        For each example, strictly follow this exact format with no deviation:

        1. Context: [Brief context in English - 1-2 sentences maximum]
        Japanese: [Complete natural Japanese sentence that uses the word "{word}"]
        Korean: [Complete natural Korean translation]

        2. Context: [Brief context in English - 1-2 sentences maximum]
        Japanese: [Complete natural Japanese sentence that uses the word "{word}"]
        Korean: [Complete natural Korean translation]

        ## Semantic Guidelines for Nouns
        - For nouns such as "å›³æ›¸é¤¨" (library), "æ–™ç†" (cooking), "å‹é”" (friend):
        - Place them in realistic contexts:
            - Location nouns (e.g. å›³æ›¸é¤¨, å…¬åœ’) should appear with verbs like "ã«è¡Œã" (to go to) or "ã§å‹‰å¼·ã™ã‚‹" (to study at)
            - Animate nouns (e.g. å‹é”, çŠ¬) should be used as subjects (ãŒ) or objects (ã‚’) in varied sentence roles
            - Abstract nouns (e.g. è‡ªç”±, å¹¸ç¦) should pair with conceptual verbs like "ã‚’æ„Ÿã˜ã‚‹" (to feel) or "ã‚’æ±‚ã‚ã‚‹" (to seek)
        - Demonstrate correct particle usage for nouns: ãŒ, ã‚’, ã«, ã®, ã§, etc.
        - Vary modifiers:
        - Adjective modifiers (e.g. "å¤§ããªå®¶", "ç¾å‘³ã—ã„æ–™ç†")
        - Quantifier expressions (e.g. "ä¸‰å†Šã®æœ¬", "äºŒäººã®å‹é”")
        - If a noun has multiple senses, present distinct situations illustrating each sense

        ## Verb and Tense Guidelines
        - å‹•è©ã€Œé£Ÿã¹ã‚‹ã€ã€Œé£²ã‚€ã€ãªã©ã¯ã€å…·ä½“çš„ãªé£Ÿã¹ç‰©ãƒ»é£²ã¿ç‰©ã‚’ç›®çš„èªã¨ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ (ä¾‹: ã€Œãƒªãƒ³ã‚´ã‚’é£Ÿã¹ã‚‹ã€ã€ã€Œã‚³ãƒ¼ãƒ’ãƒ¼ã‚’é£²ã‚€ã€).
        - æŠ½è±¡çš„ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆåè©ï¼ˆã€Œãƒ”ã‚¯ãƒ‹ãƒƒã‚¯ã€ãªã©ï¼‰ã¯ç›®çš„èªã«ã—ãªã„ã§ãã ã•ã„.
        - æ–‡è„ˆã«å¿œã˜ã¦æ™‚åˆ¶ã‚’æ˜ç¢ºã«åŒºåˆ¥ã—ã¦ãã ã•ã„ã€‚å®Œäº†ã—ãŸå‹•ä½œã«ã¯éå»å½¢(ï½ãŸ), ç¿’æ…£ãƒ»æœªæ¥ã«ã¯ç¾åœ¨å½¢(ï½ã‚‹/ï½ã¾ã™å½¢)ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
        - è¡Œå‹•å‹•è©ã‚’ä½¿ã†ã¨ãã¯ã€å¿…ãšå…·ä½“çš„ãªå¯¾è±¡ã‚„å ´æ‰€ã‚’ä¸€ç·’ã«æ˜ç¤ºã—ã¦ãã ã•ã„ (ä¾‹: ã€Œå…¬åœ’ã§ã‚µãƒ³ãƒ‰ã‚¤ãƒƒãƒã‚’é£Ÿã¹ã‚‹ã€ã€ã€Œå›³æ›¸é¤¨ã§å‹‰å¼·ã™ã‚‹ã€).
        - å…¨ã¦ã®æ–‡ã¯å®Œå…¨ãªæ–‡ã¨ã—ã¦çµ‚äº†ã•ã›ã¦ãã ã•ã„ã€‚ã€Œ...ã€ã§çµ‚ã‚ã‚‹ä¸å®Œå…¨ãªæ–‡ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚

        ## Important Notes
        - ALWAYS include the word "{word}" in each Japanese sentence
        - Each example MUST include: Context, Japanese sentence, Korean translation
        - Number each example consecutively (1-{num_examples})
        - Focus on natural, authentic Japanese as actually used by native speakers
        - DO NOT include any romanization, pronunciation guide, or English translation in the Japanese sentence
        - DO NOT put romaji, hiragana readings, or any non-Japanese explanations in parentheses
        - Japanese sentences should contain ONLY Japanese characters, nothing else
        - Do not add explanations or notes between examples
        - DO NOT add any numbering or markers at the end of Korean translations
        - ALL sentences must be COMPLETE with proper ending. NO ellipses (...) or unfinished sentences.
        """.strip()

    # ì¶”ê°€ ê²€ì¦ í•¨ìˆ˜
    @staticmethod
    def _validate_semantics(examples: List[Dict[str, str]], word: str) -> List[Dict[str, str]]:
        """
        Validates the semantic naturalness of Japanese sentences.

        This function checks for semantically inappropriate verb-object combinations,
        unnatural patterns, and formatting issues in both Japanese and Korean text.

        Args:
            examples: List of example dictionaries generated by LLM
            word: Target Japanese word to validate

        Returns:
            List of validated examples that pass semantic and formatting checks
        """

        class SemanticValidator:
            """Helper class for semantic validation of Japanese sentences"""

            # Semantic constraints for specific verbs and their inappropriate objects
            VERB_OBJECT_CONSTRAINTS = {
                "é£Ÿã¹ã‚‹": {  # "to eat"
                    "invalid_objects": [
                        "æ—¥æœ¬èª", "å‹‰å¼·", "å®¿é¡Œ", "å•é¡Œ", "è©¦é¨“", "ãƒ†ã‚¹ãƒˆ", "æ–‡æ³•", "è¨€èª",
                        "è»Š", "é›»è»Š", "å®¶", "ãƒ“ãƒ«", "å­¦æ ¡", "ä¼šç¤¾", "éŸ³æ¥½", "æ˜ ç”»", "ãƒ†ãƒ¬ãƒ“"
                    ],
                    "pattern_template": r"{obj}ã‚’é£Ÿã¹ã‚‹"
                },
                "é£²ã‚€": {  # "to drink"
                    "invalid_objects": [
                        "é›»è»Š", "è‡ªè»¢è»Š", "è»Š", "æœ¬", "æ˜ ç”»", "ãƒ†ãƒ¬ãƒ“", "å®¶", "ãƒ“ãƒ«",
                        "å®¿é¡Œ", "å•é¡Œ", "éŸ³æ¥½", "ã‚²ãƒ¼ãƒ "
                    ],
                    "pattern_template": r"{obj}ã‚’é£²ã‚€"
                },
                "é¿ã‘ã‚‹": {  # "to avoid"
                    "invalid_patterns": [r"éƒ¨å±‹ã‚’é¿ã‘ã‚‹"]  # "avoid room" is unnatural
                }
            }

            # General unnatural patterns regardless of specific words
            UNNATURAL_PATTERNS = [
                r'éƒ¨å±‹ã‚’é¿ã‘ã‚‹',  # "avoid room"
                r'è»Šã‚’é£Ÿã¹ã‚‹',  # "eat car"
                r'å®¶ã‚’é£²ã‚€',  # "drink house"
                r'å•é¡Œã‚’æ­©ã',  # "walk problem"
            ]

            # Korean translation quality patterns to filter out
            KOREAN_FORMATTING_ISSUES = [
                r'\d+\.\s*\*+',  # Numbered markers with asterisks
                r'^\d+\.',  # Lines starting with numbers
                r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]',  # Japanese characters in Korean text
            ]

            @classmethod
            def has_semantic_violation(cls, japanese_text: str, target_word: str) -> bool:
                """Check if the sentence has semantic violations for the target word"""
                if target_word not in cls.VERB_OBJECT_CONSTRAINTS:
                    return False

                constraints = cls.VERB_OBJECT_CONSTRAINTS[target_word]

                # Check verb-object constraints
                if "invalid_objects" in constraints:
                    pattern_template = constraints["pattern_template"]
                    for invalid_obj in constraints["invalid_objects"]:
                        pattern = pattern_template.format(obj=re.escape(invalid_obj))
                        if re.search(pattern, japanese_text):
                            return True

                # Check predefined invalid patterns
                if "invalid_patterns" in constraints:
                    for pattern in constraints["invalid_patterns"]:
                        if re.search(pattern, japanese_text):
                            return True

                return False

            @classmethod
            def has_unnatural_patterns(cls, japanese_text: str) -> bool:
                """Check for general unnatural patterns in Japanese text"""
                return any(re.search(pattern, japanese_text) for pattern in cls.UNNATURAL_PATTERNS)

            @classmethod
            def has_korean_formatting_issues(cls, korean_text: str) -> bool:
                """Check for formatting issues in Korean translation"""
                return any(re.search(pattern, korean_text) for pattern in cls.KOREAN_FORMATTING_ISSUES)

            @classmethod
            def clean_korean_text(cls, korean_text: str) -> str:
                """Clean and normalize Korean text"""
                # Remove multiple consecutive newlines
                cleaned = re.sub(r'\n{2,}', '\n', korean_text)
                # Remove any remaining Japanese characters
                cleaned = re.sub(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]', '', cleaned)
                return cleaned.strip()

        def is_valid_example(example: Dict[str, str]) -> bool:
            """
            Validate a single example for basic requirements and semantic correctness

            Args:
                example: Dictionary containing 'japanese' and 'korean' keys

            Returns:
                bool: True if example passes all validation checks
            """
            japanese_text = example.get('japanese', '').strip()
            korean_text = example.get('korean', '').strip()

            # Basic validation: both texts must exist and have minimum length
            if not japanese_text or not korean_text:
                return False

            if len(japanese_text) < 5 or len(korean_text) < 5:
                return False

            # Target word must be present in Japanese sentence
            if word not in japanese_text:
                return False

            # Check for semantic violations
            if SemanticValidator.has_semantic_violation(japanese_text, word):
                return False

            # Check for unnatural patterns
            if SemanticValidator.has_unnatural_patterns(japanese_text):
                return False

            # Check Korean formatting issues
            if SemanticValidator.has_korean_formatting_issues(korean_text):
                return False

            return True

        # Process and validate examples
        validated_examples = []

        for example in examples:
            if is_valid_example(example):
                # Clean Korean text before adding to validated list
                example['korean'] = SemanticValidator.clean_korean_text(example['korean'])
                validated_examples.append(example)

        # Return validated examples or error message if none are valid
        if validated_examples:
            return validated_examples
        else:
            return [{
                "context": "",
                "japanese": "é©åˆ‡ãªä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
                "korean": "ì ì ˆí•œ ì˜ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            }]

    @staticmethod
    def _parse_examples(response_text: str, word: str) -> List[Dict[str, str]]:
        """
        Extract Japanese examples and translations from the LLM response.

        Args:
            response_text: Text response from the LLM
            word: Target Japanese word for validation

        Returns:
            List of dictionaries with context, Japanese, and Korean fields
        """
        examples = []

        # Debug - log response for troubleshooting
        app.logger.debug("Response from LLM (first 500 chars): " +
                         (response_text[:500] + "..." if len(response_text) > 500 else response_text))

        # Main pattern: Find examples with Context/Japanese/Korean labels
        main_pattern = r'(?:\d+\.\s*)?Context:\s*(.*?)\s*Japanese:\s*(.*?)\s*Korean:\s*(.*?)(?=\s*(?:\d+\.\s*)?Context:|\s*$)'
        matches = re.findall(main_pattern, response_text, re.DOTALL)

        if matches:
            app.logger.debug(f"Found {len(matches)} examples with the main pattern")
            for match in matches:
                context, japanese, korean = match

                # ë¶ˆì™„ì „í•œ ë¬¸ì¥ í™•ì¸ (1): ë¬¸ì¥ì´ "..." ë˜ëŠ” "â€¦"ë¡œ ëë‚˜ëŠ” ê²½ìš°
                if japanese.strip().endswith('...') or japanese.strip().endswith('â€¦'):
                    app.logger.debug(f"Skipping incomplete sentence: {japanese}")
                    continue

                # ë¶ˆì™„ì „í•œ ë¬¸ì¥ í™•ì¸ (2): ë¬¸ì¥ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ì€ ê²½ìš°
                if len(japanese.strip()) < 10:
                    app.logger.debug(f"Skipping too short sentence: {japanese}")
                    continue

                # ë¡œë§ˆì í‘œê¸° ì œê±° (ê´„í˜¸ì™€ ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±°)
                japanese = re.sub(r'\s*\([^)]*\)', '', japanese)

                # Clean Korean translation from any Japanese characters
                korean = re.sub(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]', '', korean)

                # ì¶”ê°€ ì •ì œ: ë²ˆì—­ì—ì„œ ìˆ«ìì™€ ë§ˆì»¤ ì œê±°
                korean = re.sub(r'\d+\.\s*\*+', '', korean)
                korean = re.sub(r'^\d+\.\s*', '', korean)

                # ì—¬ëŸ¬ ì¤„ ë°”ê¿ˆ ì •ë¦¬
                korean = re.sub(r'\n{2,}', '\n', korean)

                examples.append({
                    "context": context.strip(),
                    "japanese": japanese.strip(),
                    "korean": korean.strip()
                })

        # If main pattern doesn't find anything, try alternative pattern
        if not examples:
            # Numbered example pattern
            numbered_pattern = r'(\d+)\.[\s\n]+(.*?)[\s\n]+Japanese:[\s\n]+(.*?)[\s\n]+Korean:[\s\n]+(.*?)(?=[\s\n]+\d+\.|\s*$)'
            matches = re.findall(numbered_pattern, response_text, re.DOTALL)

            if matches:
                app.logger.debug(f"Found {len(matches)} examples with the numbered pattern")
                for match in matches:
                    number, context, japanese, korean = match

                    # ë¶ˆì™„ì „í•œ ë¬¸ì¥ í™•ì¸ (1): ë¬¸ì¥ì´ "..." ë˜ëŠ” "â€¦"ë¡œ ëë‚˜ëŠ” ê²½ìš°
                    if japanese.strip().endswith('...') or japanese.strip().endswith('â€¦'):
                        app.logger.debug(f"Skipping incomplete sentence: {japanese}")
                        continue

                    # ë¶ˆì™„ì „í•œ ë¬¸ì¥ í™•ì¸ (2): ë¬¸ì¥ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ì€ ê²½ìš°
                    if len(japanese.strip()) < 10:
                        app.logger.debug(f"Skipping too short sentence: {japanese}")
                        continue

                    # ë¡œë§ˆì í‘œê¸° ì œê±° (ê´„í˜¸ì™€ ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±°)
                    japanese = re.sub(r'\s*\([^)]*\)', '', japanese)

                    # Clean Korean translation from any Japanese characters
                    korean = re.sub(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]', '', korean)

                    # ì¶”ê°€ ì •ì œ: ë²ˆì—­ì—ì„œ ìˆ«ìì™€ ë§ˆì»¤ ì œê±°
                    korean = re.sub(r'\d+\.\s*\*+', '', korean)
                    korean = re.sub(r'^\d+\.\s*', '', korean)

                    # ì—¬ëŸ¬ ì¤„ ë°”ê¿ˆ ì •ë¦¬
                    korean = re.sub(r'\n{2,}', '\n', korean)

                    examples.append({
                        "context": context.strip(),
                        "japanese": japanese.strip(),
                        "korean": korean.strip()
                    })

        # ë‹¤ì‹œ í•œë²ˆ ë¶ˆì™„ì „í•œ ë¬¸ì¥ í•„í„°ë§
        filtered_examples = []
        for example in examples:
            japanese = example.get('japanese', '')
            korean = example.get('korean', '')

            # ë¬¸ì¥ì´ ëë‚˜ì§€ ì•Šì€ ê²½ìš° í•„í„°ë§
            if (japanese.endswith('...') or japanese.endswith('â€¦') or
                    len(japanese) < 10 or word not in japanese or
                    not korean or len(korean) < 5):
                continue

            filtered_examples.append(example)

        # Semantic validation using _validate_semantics
        if filtered_examples:
            validated_examples = JapaneseExampleGenerator._validate_semantics(filtered_examples, word)

            # Check if we have enough examples after validation
            if validated_examples and not all(
                    ex.get('japanese') == "é©åˆ‡ãªä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚" for ex in validated_examples):
                return validated_examples

        # ìµœì†Œ ì˜ˆì‹œ ê°œìˆ˜ê°€ ì¶©ì¡±ë˜ì§€ ì•Šì€ ê²½ìš°, ë‹¤ì‹œ í•œë²ˆ LLM í˜¸ì¶œ ì‹œë„
        if len(filtered_examples) < 2:
            app.logger.warning("Not enough valid examples. Returning error message.")
            return [{"context": "", "japanese": "ä¾‹æ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "korean": "ì˜ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}]

        return filtered_examples

    @staticmethod
    def _build_word_info_prompt(word: str) -> str:
        """
        Build the prompt for getting word information.

        Args:
            word: Japanese word to analyze

        Returns:
            Formatted prompt string
        """
        return f"""
        # Comprehensive Japanese Word Analysis Request

        ## Target Word
        {word}

        ## Task
        Provide comprehensive and accurate linguistic information about this Japanese word.

        ## Content Requirements
        Please include the following information:

        ### 1. Basic Information
        - Part of speech: Precise classification (noun, verb, adjective, adverb, etc.)
        - Reading: How the word is pronounced
        - Kanji representation: If applicable
        - Etymology: Origins of the word if available
        - Usage frequency: How commonly the word is used in daily conversation, literature, business, etc.
        - Politeness level: Honorific, neutral, casual, etc.

        ### 2. Meaning Information
        - Basic meaning: Core definition
        - Additional meanings: Secondary definitions
        - Nuances and connotations: Subtle implications
        - Contextual variations: How meaning changes in different contexts

        ### 3. Usage Examples
        - Daily conversation examples (2-3)
        - Written language examples (1-2)
        - Special situation examples (1-2)
        - Idiomatic expressions or proverbs using the word (1-2 if applicable)

        ### 4. Related Expressions
        - Synonyms (3-4 words)
        - Antonyms (1-2 if applicable)
        - Related expressions and collocations (3-4)
        - Derivative words (2-3 if applicable)

        ### 5. Grammatical Information

        #### For Verbs:
        - Conjugation group (Godan, Ichidan, Irregular, etc.)
        - Main conjugation forms:
          * Dictionary form
          * Masu form
          * Te form
          * Nai form (negative)
          * Ta form (past)
          * Volitional form
          * Potential form
          * Passive form
          * Causative form
          * Conditional form
          * Imperative form
        - Transitivity (transitive/intransitive distinction)
        - Common particle patterns and grammatical constructions

        #### For Adjectives:
        - Adjective type (i-adjective/na-adjective)
        - Main conjugation forms:
          * Basic form
          * Polite form (desu form)
          * Negative form
          * Past form
          * Negative past form
          * Adverbial form
          * Conditional form
        - Common combination patterns

        #### For Nouns:
        - Particle combination patterns
        - Common verbs used with this noun
        - Compound word formation
        - Count/non-count distinction (if applicable)

        ### 6. Cultural/Contextual Information
        - Cultural background
        - Historical development
        - Generational/regional usage differences
        - Social implications

        ## Output Format
        Structure your response in two sections - first in Japanese, then the same information in Korean:

        === æ—¥æœ¬èª ===
        ã€å“è©ã€‘
        ã€èª­ã¿æ–¹ã€‘
        ã€æ¼¢å­—è¡¨è¨˜ã€‘(è©²å½“ã™ã‚‹å ´åˆ)
        ã€èªæºã€‘(è©²å½“ã™ã‚‹å ´åˆ)
        ã€åŸºæœ¬çš„ãªæ„å‘³ã€‘
        ã€è¿½åŠ çš„ãªæ„å‘³ãƒ»ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã€‘
        ã€ä½¿ç”¨é »åº¦ãƒ»å ´é¢ã€‘
        ã€æ•¬èªãƒ¬ãƒ™ãƒ«ã€‘
        ã€æ—¥å¸¸ä¼šè©±ã§ã®ä¾‹æ–‡ã€‘
        ã€æ–‡èªä½“ã®ä¾‹æ–‡ã€‘
        ã€ç‰¹æ®ŠãªçŠ¶æ³ã§ã®ä¾‹æ–‡ã€‘
        ã€æ…£ç”¨å¥ãƒ»ã“ã¨ã‚ã–ã€‘(è©²å½“ã™ã‚‹å ´åˆ)
        ã€é¡ç¾©èªãƒ»åŒç¾©èªã€‘
        ã€å¯¾ç¾©èªã€‘(è©²å½“ã™ã‚‹å ´åˆ)
        ã€é–¢é€£è¡¨ç¾ãƒ»ã‚³ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‘
        ã€æ´¾ç”Ÿèªã€‘(è©²å½“ã™ã‚‹å ´åˆ)
        ã€æ–‡æ³•æƒ…å ±ã€‘
        * æ´»ç”¨ã‚°ãƒ«ãƒ¼ãƒ—(å‹•è©ã®å ´åˆ)
        * ä¸»ãªæ´»ç”¨å½¢
        * è‡ªå‹•è©ãƒ»ä»–å‹•è©ã®åŒºåˆ¥(å‹•è©ã®å ´åˆ)
        * çµåˆãƒ‘ã‚¿ãƒ¼ãƒ³
        ã€æ–‡åŒ–çš„ãƒ»ç¤¾ä¼šçš„æƒ…å ±ã€‘

        === í•œêµ­ì–´ ===
        ã€í’ˆì‚¬ã€‘
        ã€ì½ëŠ” ë²•ã€‘
        ã€í•œì í‘œê¸°ã€‘(í•´ë‹¹ë˜ëŠ” ê²½ìš°)
        ã€ì–´ì›ã€‘(í•´ë‹¹ë˜ëŠ” ê²½ìš°)
        ã€ê¸°ë³¸ì ì¸ ì˜ë¯¸ã€‘
        ã€ì¶”ê°€ì ì¸ ì˜ë¯¸ãƒ»ë‰˜ì•™ìŠ¤ã€‘
        ã€ì‚¬ìš© ë¹ˆë„ãƒ»ìƒí™©ã€‘
        ã€ê²½ì–´ ìˆ˜ì¤€ã€‘
        ã€ì¼ìƒ ëŒ€í™” ì˜ˆë¬¸ã€‘
        ã€ë¬¸ì–´ì²´ ì˜ˆë¬¸ã€‘
        ã€íŠ¹ìˆ˜ ìƒí™© ì˜ˆë¬¸ã€‘
        ã€ê´€ìš©êµ¬ãƒ»ì†ë‹´ã€‘(í•´ë‹¹ë˜ëŠ” ê²½ìš°)
        ã€ìœ ì˜ì–´ãƒ»ë™ì˜ì–´ã€‘
        ã€ë°˜ì˜ì–´ã€‘(í•´ë‹¹ë˜ëŠ” ê²½ìš°)
        ã€ê´€ë ¨ í‘œí˜„ãƒ»ì—°ì–´ã€‘
        ã€íŒŒìƒì–´ã€‘(í•´ë‹¹ë˜ëŠ” ê²½ìš°)
        ã€ë¬¸ë²• ì •ë³´ã€‘
        * í™œìš© ê·¸ë£¹(ë™ì‚¬ì¸ ê²½ìš°)
        * ì£¼ìš” í™œìš©í˜•
        * ìë™ì‚¬ãƒ»íƒ€ë™ì‚¬ êµ¬ë³„(ë™ì‚¬ì¸ ê²½ìš°)
        * ê²°í•© íŒ¨í„´
        ã€ë¬¸í™”ì ãƒ»ì‚¬íšŒì  ì •ë³´ã€‘

        ## Important Notes
        - DO NOT include any English in your actual response content (only in the template headers)
        - Keep your entire response under 600 words
        - Focus on clear, accurate linguistic information
        - Use natural, everyday Japanese for examples
        - You don't need to fill in all categories if they're not applicable to this word
        - Omit irrelevant information based on the word type (e.g., skip verb conjugation info for nouns)
        """.strip()

    @staticmethod
    def format_output(examples: List[Dict[str, str]]) -> str:
        """
        Format examples into a concise output string.

        Args:
            examples: List of example dictionaries
            include_furigana: Whether to add furigana readings (optional feature for later)

        Returns:
            Formatted output string
        """
        result = ""
        for i, example in enumerate(examples, 1):
            result += f"ğŸ“ ì˜ˆì‹œ {i}\n"

            if example.get('japanese') and example['japanese'].strip():
                result += f"ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´: {example['japanese']}\n"
                result += f"ğŸ‡°ğŸ‡· í•œêµ­ì–´: {example['korean']}\n\n"

        # If no examples were formatted
        if not result:
            result = "ì˜ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"

        return result


# Flask routes

@app.route('/api/examples', methods=['POST'])
def api_examples():
    """API endpoint for generating examples."""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "JSON ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        word = data.get('word')
        level = data.get('level', Config.DEFAULT_DIFFICULTY)
        format_type = data.get('format', 'simple')  # 'simple', 'with_hiragana', 'with_context'

        if not word:
            return jsonify({"error": "ë‹¨ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        if level.lower() not in Config.VALID_LEVELS:
            level = Config.DEFAULT_DIFFICULTY

        # Generate examples
        examples = JapaneseExampleGenerator.generate_examples(word, level.lower())

        # ì‘ë‹µ í˜•ì‹ì— ë”°ë¼ ë‹¤ë¥¸ ì¶œë ¥ êµ¬ì„±
        if format_type == 'simple':
            # ê°€ì¥ ê¸°ë³¸ í˜•ì‹: ì¼ë³¸ì–´ì™€ í•œêµ­ì–´ë§Œ í¬í•¨
            examples_clean = [
                {
                    "japanese_example": ex.get("japanese", "").strip(),
                    "korean_translation": ex.get("korean", "").strip()
                }
                for ex in examples
            ]
        elif format_type == 'with_context':
            # ì»¨í…ìŠ¤íŠ¸ í¬í•¨ í˜•ì‹
            examples_clean = examples
        elif format_type == 'with_hiragana':
            # íˆë¼ê°€ë‚˜ ë…ìŒ ì¶”ê°€ (ì´ ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ í•„ìš”)
            # í˜„ì¬ëŠ” ë‹¨ìˆœíˆ ì¼ë³¸ì–´ì™€ í•œêµ­ì–´ë§Œ í¬í•¨
            examples_clean = [
                {
                    "japanese_example": ex.get("japanese", "").strip(),
                    "korean_translation": ex.get("korean", "").strip()
                }
                for ex in examples
            ]
            # í–¥í›„ íˆë¼ê°€ë‚˜ ë³€í™˜ API ë“±ì„ í†µí•´ ë…ìŒ ì¶”ê°€ ê°€ëŠ¥
        else:
            # ê¸°ë³¸ í˜•ì‹
            examples_clean = [
                {
                    "japanese_example": ex.get("japanese", "").strip(),
                    "korean_translation": ex.get("korean", "").strip()
                }
                for ex in examples
            ]

        # Return examples
        return jsonify({"examples": examples_clean})

    except Exception as e:
        app.logger.error(f"Example generation error: {str(e)}")
        return jsonify({"error": f"ì˜ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500


# Command-line interface
def main():
    """
    Command-line interface for the Japanese example generator.
    Handles user input, word lookup, example generation, etc.
    """
    print("\n" + "=" * 50)
    print("ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´ ì˜ˆë¬¸ ìƒì„±ê¸° ğŸ‡¯ğŸ‡µ")
    print("ìì—°ìŠ¤ëŸ¬ìš´ ì¼ë³¸ì–´ ì˜ˆë¬¸ê³¼ í•œêµ­ì–´ ë²ˆì—­ì„ ìƒì„±í•©ë‹ˆë‹¤")
    print("=" * 50)
    print("â€¢ ë‹¨ì–´ ì •ë³´ë¥¼ ë³´ë ¤ë©´ 'info [ë‹¨ì–´]'ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    print("â€¢ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
    print("=" * 50 + "\n")

    while True:
        try:
            # Get user input
            user_input = input("\nğŸ‘‰ ì¼ë³¸ì–´ ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë˜ëŠ” 'info [ë‹¨ì–´]'): ").strip()

            # Skip empty input
            if not user_input:
                continue

            # Check if user wants word information
            if user_input.lower().startswith('info '):
                word = user_input[5:].strip()  # Extract word after 'info '
                if not word:
                    print("âŒ 'info' ë’¤ì— ë‹¨ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
                    continue

                print(f"\nğŸ“š '{word}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘...")
                word_info = JapaneseExampleGenerator.get_word_info(word)
                print("\n" + word_info)
                continue

            # Use entered word for example generation
            word = user_input

            # Get JLPT level input
            difficulty_input = input("ğŸ¯ JLPT ë ˆë²¨ (n5/n4/n3/n2/n1) ë˜ëŠ” 'standard' (ê¸°ë³¸ê°’: n3): ").strip().lower()

            # Validate and set difficulty
            if difficulty_input and difficulty_input in Config.VALID_LEVELS:
                difficulty = difficulty_input
            else:
                if difficulty_input and difficulty_input not in Config.VALID_LEVELS:
                    print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ë ˆë²¨ '{difficulty_input}', ê¸°ë³¸ê°’(n3)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                difficulty = Config.DEFAULT_DIFFICULTY

            # Display format
            display_difficulty = difficulty.upper() if difficulty in ["n5", "n4", "n3", "n2", "n1"] else difficulty
            print(f"\nğŸ” '{word}'ë¥¼ ì‚¬ìš©í•œ {display_difficulty} ë ˆë²¨ ì˜ˆë¬¸ì„ ìƒì„± ì¤‘...")

            # Generate and display examples
            try:
                examples = JapaneseExampleGenerator.generate_examples(word, difficulty)
                print("\nâœ¨ ìƒì„±ëœ ì˜ˆë¬¸:")
                print(JapaneseExampleGenerator.format_output(examples))

            except Exception as e:
                print(f"âŒ ì˜ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                print("ë‹¤ë¥¸ ë‹¨ì–´ë‚˜ ì„¤ì •ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ì¼ë³¸ì–´ ì˜ˆë¬¸ ìƒì„±ê¸°ë¥¼ ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì•ˆë…•íˆ ê°€ì„¸ìš”.")
            break
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=3000, debug=True)
